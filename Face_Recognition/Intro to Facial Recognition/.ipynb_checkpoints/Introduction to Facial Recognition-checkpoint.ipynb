{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "---\n",
    "* Understand how it works\n",
    "* Case study\n",
    "* Implementation\n",
    "* Understanding the Implementation\n",
    "* Applications of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand how it works\n",
    "---\n",
    "### Feature vector\n",
    "---\n",
    "In general, ML algorithms take a dataset as input and learn from the given data. The algorithm goes through the data and identifies patterns. To identify whose face is present in a given image, we could look at multiple things to find a pattern:\n",
    "* Heigh/width of the face. It might not be reliable since the image could be rescaled to a smaller face. However, even after rescaling, what remains unchanged are the ratios – they won't change.\n",
    "* Colour of the face.\n",
    "* Width of other parts of the face like nose, lips, etc.\n",
    "\n",
    "As you can see, clearly there is a pattern as different faces have different dimensions. Similar faces have similar dimensions.\n",
    "\n",
    "The main challenge is to convert a particular face into numbers – ML algorithms only understand numbers. Therefore, the numerical representation of a \"face\" (or any element in the training set) is termed as a **feature vector**, compromising various numbers in a specific order.\n",
    "\n",
    "As a simple example, we can map a \"face\" into a feature vector which can compromise features like:\n",
    "* Height of face (cm)\n",
    "* Width of face (cm)\n",
    "* Average colour of face (RGB)\n",
    "* Width of lips (cm)\n",
    "* Height of nose (cm)\n",
    "\n",
    "We can then convert it to a feature vector like:\n",
    "\n",
    "| Height of face (cm) | Width of face (cm) | Average colour of face (RGB) | Width of lips (cm) | Height of nose (cm) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 23.1 | 15.8 | (255, 224, 189) | 5.2 | 4.4 |\n",
    "\n",
    "Therefore, the vector could be represented as (23.1, 15.8, 255, 224, 189, 5.2, 4.4).\n",
    "\n",
    "Obviously there could be countless other features that could be derived from the image (for instance, hair colour, facial hair, glasses, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After encoding each image into a feature vector\n",
    "---\n",
    "Now that everything is encoded, the problem becomes much simpler.\n",
    "Clearly, when we have 2 faces (images) that represent the same person, the feature vectors derived will be quite similar. **The \"distance\" between the 2 feature vectors will be quite small!**.\n",
    "\n",
    "ML can help with 2 things:\n",
    "1. *Deriving the feature vector*: it is difficult to manually list down all of the features because there are too many. A ML algorithm can intelligently label out many of such features. For example, a complex feature could be: ratio of height of nose and width of forehead. Now it will be quite difficult for a human to list down all such \"second order\" features.\n",
    "2. *Matching algorithms*: a ML algorithm needs to match a new image with the set of feature vectors present in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "---\n",
    "We are given a bunch of faces – possibly of celebrities like Mark Zuckerberg, Warren Buffett, Bill Gates, Shah Rukh Khan, etc. Call this bunch of faces as our \"corpus\". Now, we are given image of yet another celebrity (\"new celebrity\"). The task is simple – identify if this \"new celebrity\" is among those present in the \"corpus\".\n",
    "\n",
    "Here are some of the images in the corpus:\n",
    "\n",
    "![faces](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/face1.png \"Some faces!\")\n",
    "\n",
    "Now here is the \"new celebrity\":\n",
    "![faces](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/face2.png \"Some faces!\")\n",
    "\n",
    "There is a simple Python library that encapsulates all of what we learn above – creating features vectors out of faces and knowing how to differentiate across faces. The library is called **face_recognition** and deep within, it employs **dlib** – a modern C++ toolkit that contains several ML algorithms that help in writing sophisticated C++ based applications.\n",
    "\n",
    "**face_recognition** library in Python can perform a large number of tasks:\n",
    "* Find all the faces in a given image\n",
    "* Find and manipulate facial features in an image\n",
    "* Identify faces in image\n",
    "* Real-time face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "---\n",
    "This section covers the code for building a straightforward face recognition system using the mentioned libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "#make a list of all the available images\n",
    "images = os.listdir('images')\n",
    "\n",
    "#load image\n",
    "image_to_be_matched = face_recognition.load_image_file('guess.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into a feature vector\n",
    "image_to_be_matched_encoded = face_recognition.face_encodings(image_to_be_matched)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not matched: hunter.jpg\n",
      "Not matched: kaitlyn.jpg\n",
      "Not matched: mikaela.jpg\n",
      "Matched: brie.jpg\n",
      "Not matched: zendaya.jpg\n",
      "Not matched: barbie.jpg\n",
      "Not matched: diana.jpg\n"
     ]
    }
   ],
   "source": [
    "#iterate over each image\n",
    "for image in images:\n",
    "    #load\n",
    "    current_image = face_recognition.load_image_file(\"images/\"+image)\n",
    "    #turn into feature vector\n",
    "    current_image_encoded = face_recognition.face_encodings(current_image)[0]\n",
    "    #match with the iamge and check if it matches\n",
    "    result = face_recognition.compare_faces(\n",
    "    [image_to_be_matched_encoded], current_image_encoded)\n",
    "    #check if it was a match\n",
    "    if result[0] == True:\n",
    "        print(\"Matched: \" + image)\n",
    "    else:\n",
    "        print(\"Not matched: \" + image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
