{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Embedding\n",
    "\n",
    "* It is a vector that represents the features extracted from the face. It can then be compared with vectors generated for other faces. To better explain, for example, another vector that is close may be the same person, whereas another vector that is far may be a different person.\n",
    "\n",
    "* This classifier model will take a face embedding as input and predict the identity of the face.\n",
    "\n",
    "* The FaceNet model can be used as part of the classifier itself, or it can be used to pre-process a face to create a face embedding that can be stored and used as input to the classifier model. The latter approach is preferred as the FaceNet model is both large and slow to create a face embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can load our dataset using the load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "data = load('compressed_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x10c4f28d0>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " trainX:  (92, 160, 160, 3) \n",
      " trainy:  (92,) \n",
      " testX:  (25, 160, 160, 3) \n",
      " testy:  (25,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded:\\n',\n",
    "      'trainX: ', trainX.shape ,'\\n',\n",
    "      'trainy: ', trainy.shape ,'\\n',\n",
    "      'testX: ', testX.shape ,'\\n',\n",
    "      'testy: ', testy.shape ,'\\n',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 11:15:13.412560 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 11:15:13.511946 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 11:15:13.541748 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 11:15:13.543135 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0715 11:15:13.545151 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0715 11:15:13.591962 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0715 11:15:13.877161 4362679744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0715 11:15:26.373093 4362679744 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('model/facenet_keras.h5')\n",
    "print('Loaded Model!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then enumerate each face in the train and test dataset to predict an embedding.\n",
    "\n",
    "To predict an embedding, the pixel values of the image need to be suitably prepared to meet the expectations of the model. This implementation of the FaceNet model expects that the pixel values are **standardized**.\n",
    "\n",
    "The script would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "#get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    #scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    #standardize pixel values across channels\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    #transform face into one single sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    #make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tying everything together and loading everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 128)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "#convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 128)\n"
     ]
    }
   ],
   "source": [
    "#same thing for the test set\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "#save arrays to one file, compressed\n",
    "savez_compressed('compressed_face-embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transformed the train dataset into 92 face embeddings, each comprised of a 128 element vector.\n",
    "\n",
    "The 25 examples in the test dataset were also converted to face embeddings of 128."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
